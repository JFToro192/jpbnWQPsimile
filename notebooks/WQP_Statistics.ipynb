{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at computing the descriptive statistics for the WQP maps, or any raster, by defining specific features from which these statistics are requested (located within the [in](./in) folder). In addition, the analysis of the WQP maps will consider de extraction of sampling data inside the pixels to review the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling notebook\n",
    "\n",
    "# System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import scripts libraries for the project\n",
    "sys.path.append('./src/python')\n",
    "\n",
    "# Import the function to update the notebook style\n",
    "from nbConfig import (css_styling)\n",
    "\n",
    "\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "font = {'family' : 'Georgia',\n",
    "#         'weight' : 'bold',\n",
    "        'size'   : 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Spatial Data\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn as sns\n",
    "from rasterio.plot import show_hist\n",
    "import ipywidgets as wg\n",
    "\n",
    "# Import custom libraries\n",
    "import wqpFunctions as wqp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the working directory for the WQP processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Working Directories\n",
    "cwd = {\n",
    "    'local': '.',\n",
    "    'in': './in/wqp/',\n",
    "    'out': './out/outlier_rejection',\n",
    "    'vector': './vector',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the vector files for data extraction of the WQP maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer dataset\n",
    "gdf_lakes = gpd.read_file(os.path.join(cwd['vector'],'simile_laghi','simile_laghi.shp'))\n",
    "# Buoy position in the lake\n",
    "gdf_buoy = gpd.read_file(os.path.join(cwd['vector'],'boa_sample_points','boa_sample_points.shp'))\n",
    "# Random sampling points\n",
    "gdf_sample = gpd.read_file(os.path.join(cwd['vector'],'random_points','random_points.shp'))\n",
    "# Buffer of the extent of the lakes\n",
    "gdf_buffer = gpd.read_file(os.path.join(cwd['vector'],'simile_laghi_bboxes','simile_laghi_bboxes.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, different vector layers are needed to carry out the following statistical analysis of the results form the WQP production. The next statement presents the lake's delineation along with the sampling points. The lake's delineation, extracted from the [Carta Tecnica Regionale 1:10.000 - CT10](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BD42AE439-06FE-4E4E-93CF-ECDC9B564118%7D) available at the [Lombardy Region GeoPortal](https://www.geoportale.regione.lombardia.it/), is used for the computation of the descriptive statistics of the lakes WQP parameters per lake. While the second vector file are ranodmly generated random point for the statistical analysis of the WQP maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.rc('font', **font)\n",
    "gdf_lakes.plot(ax = ax, color= 'blue', edgecolor='k', alpha = 0.3)\n",
    "gdf_sample.plot(ax = ax, color='red')\n",
    "gdf_buoy.plot(ax = ax, color='green')\n",
    "\n",
    "scale = ScaleBar(\n",
    "    dx=1,\n",
    "    location='lower right',  # in relation to the whole plot\n",
    "    label_loc='left', scale_loc='bottom',  # in relation to the line\n",
    ")\n",
    "\n",
    "ax.set_title('Sampling Points')\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel('[m]')\n",
    "ax.set_ylabel('[m]')\n",
    "ax.add_artist(scale)\n",
    "ax.legend(['Sampling Points','Buoys Location'])\n",
    "ax.ticklabel_format(axis='both', style='sci', scilimits=(5,4))\n",
    "\n",
    "ax.arrow(4.6e5,5.11e6,0,1000)\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig('./figs/sampling_points.png',dpi=300,Transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding boxes for the statistical analysis for each lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.rc('font', **font)\n",
    "gdf_buffer.plot(ax = ax, edgecolor='k', alpha = 0.5)\n",
    "gdf_lakes.plot(ax = ax, color= 'blue', edgecolor='k', alpha = 0.3)\n",
    "# gdf_sample.plot(ax = ax, color='red')\n",
    "# gdf_buoy.plot(ax = ax, color='green')\n",
    "\n",
    "scale = ScaleBar(\n",
    "    dx=1,\n",
    "    location='lower right',  # in relation to the whole plot\n",
    "    label_loc='left', scale_loc='bottom',  # in relation to the line\n",
    ")\n",
    "\n",
    "ax.set_title('Lakes bounding boxes extend - buffer 600m')\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel('[m]')\n",
    "ax.set_ylabel('[m]')\n",
    "ax.add_artist(scale)\n",
    "ax.legend(['Buffer'])\n",
    "ax.ticklabel_format(axis='both', style='sci', scilimits=(5,4))\n",
    "\n",
    "ax.arrow(4.6e5,5.11e6,0,1000)\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig('./figs/bounding_boxes.png',dpi=300,Transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the contents of the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select WQP and Outlier Rejection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier rejection methods implemented within this work consider different filters. For the production of the WQP maps, the 3$\\sigma$ has been selected as the default filter for the identification and extraction of the outliers from the WQP outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_LIST = ['S3','L8','EUMETSAT']\n",
    "sensor = wg.Select(\n",
    "    options = SENSOR_LIST,\n",
    "    value = SENSOR_LIST[1],\n",
    "    description = 'Select the sensor:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='20%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WQP_LIST = ['chl','tsm','lswt']\n",
    "wqpMaps = wg.Select(\n",
    "    options = WQP_LIST,\n",
    "    value = WQP_LIST[2],\n",
    "    description = 'Select the wqp:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='15%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIERS_METHOD_LIST = ['IQR','2Sigma','3Sigma']\n",
    "outlierMethods = wg.Select(\n",
    "    options = OUTLIERS_METHOD_LIST,\n",
    "    value = OUTLIERS_METHOD_LIST[0],\n",
    "    description = 'Select the outlier method:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='30%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_PROD_LIST = ['wqp','wqp_cloud_mask','wqp_no_clip','wqp_no_mask','wqp_high_clouds','wqp_mid_high_clouds', 'full_outlierRejection']#last 2 L8\n",
    "refProducts = wg.Select(\n",
    "    options = REF_PROD_LIST,\n",
    "    value = REF_PROD_LIST[4],\n",
    "    description = 'Select ref product:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='35%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.HBox([sensor,wqpMaps, outlierMethods,refProducts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WQP Descriptive Statistics and Sampling Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp_parameter = 'chl'\n",
    "# in_path = f'./temp/wqp_maps/original/{wqp_parameter}'\n",
    "# out_path = f'./temp/wqp_maps/original/{wqp_parameter}'\n",
    "# in_path = f'./out/outlier_rejection/wqp/3Sigma/lswt'\n",
    "# out_path = f'./out/outlier_rejection/wqp/3Sigma/lswt'\n",
    "# in_path = './in/wqp/L8/wqp_high_clouds/lswt'\n",
    "# out_path = './in/wqp/L8/wqp_high_clouds/lswt'\n",
    "# in_path = './temp/lswt'\n",
    "# out_path = './temp/lswt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_files = os.listdir(out_path)\n",
    "# rename_files\n",
    "# for f in rename_files:\n",
    "#     if f.endswith('tif'):\n",
    "#         name = '_'.join(f.split('_')[:-1])+'.tif'\n",
    "#         os.rename(f'{out_path}/{f}', f'{out_path}/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered_or/3Sigma/{wqp_parameter}')\n",
    "# out_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered_or/3Sigma/{wqp_parameter}/outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in_path = os.path.join(f'./in/wqp/S3/wqp/{wqp_parameter}')\n",
    "# in_path = os.path.join(f'./in/wqp/EUMETSAT/{wqp_parameter}')\n",
    "# in_path = os.path.join('./extract_lswt')\n",
    "# in_path = os.path.join('./in/data/wqp/L8/wqp_high_clouds/lswt/cropped')\n",
    "# in_path = os.path.join('./out/OutlierRejection/wqp/3Sigma/lswt')\n",
    "# in_path = os.path.join(cwd['out'],'wqp',outlierMethods.value, wqpMaps.value)\n",
    "# in_path = os.path.join('./out/Coregistration/wqp/S3/full/chl')\n",
    "in_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered/{wqp_parameter}')\n",
    "# in_path = os.path.join(f'./extra/diff_maps/{wqp_parameter}')\n",
    "# in_path = os.path.join('./out/Coregistration/wqp/S3/full_outlierRejection/3Sigma/tsm')\n",
    "# out_path = os.path.join(f'./in/wqp/S3/wqp/{wqp_parameter}/cropped')\n",
    "# out_path = os.path.join(f'./in/wqp/EUMETSAT/{wqp_parameter}/cropped')\n",
    "# out_path = os.path.join(cwd['out'],'wqp',outlierMethods.value, wqpMaps.value)\n",
    "# out_path = os.path.join('./out/OutlierRejection/wqp/3Sigma/lswt')\n",
    "# out_path = os.path.join('./out/Coregistration/wqp/S3/full_outlierRejection/3Sigma/tsm')\n",
    "out_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered/{wqp_parameter}/cropped')\n",
    "# out_path = os.path.join(f'./extra/diff_maps/{wqp_parameter}/cropped')\n",
    "# out_path = os.path.join('./extract_lswt')\n",
    "\n",
    "\n",
    "issue_files = []\n",
    "arr = []\n",
    "for root, dirs, files in os.walk(out_path):\n",
    "    for file in files:\n",
    "        try:\n",
    "            print(file)\n",
    "            # Verify check if the stats and products have been computed\n",
    "            if ((file.endswith('_L1.tif')) ):\n",
    "                # if (file.split('.') not in os.listdir(in_path)):\n",
    "                    f = os.path.join(out_path,file)\n",
    "                    # Read file\n",
    "                    src = wqp.wqp(f)\n",
    "                    src.readWQP()\n",
    "                    # print(src.name)\n",
    "#                     src.name\n",
    "                    # Export dataset (check no data values)\n",
    "                    # t = src.image.read(1)\n",
    "                    # t = np.nan_to_num(t)\n",
    "                    # t[t<=0] = np.nan\n",
    "                    # src.writeWQP(os.path.join(out_path,src.name+'.tif'),t)\n",
    "\n",
    "                    # Extract information from sampling points\n",
    "                    # src.extractSamplePoints(gdf_sample)\n",
    "                    # src.extractSamplePoints(gdf_buoy)\n",
    "                    # src.samplePoint.to_csv(os.path.join('./out','sample_points',src.name+'.csv'))\n",
    "\n",
    "                    # Compute statistics for the lakes polygons\n",
    "                    src.computeStatistics(gdf_buffer, 'Nome',\"count min mean max median std  percentile_25 percentile_50 percentile_75\",-9999)\n",
    "\n",
    "                    # Format output\n",
    "                    df = wqp.wqp.exportWQPFormatStats(src)\n",
    "                    arr.append(df)\n",
    "#                     # Export the statistics result to a file (append data if existing)\n",
    "#                     out_file = os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv')\n",
    "# #                     print(out_path,f'lakesStats_{wqpMaps.value}.csv')\n",
    "#                     if os.path.exists(out_file):\n",
    "#                         df.to_csv(os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv'),mode='a', header=False)\n",
    "#                     else:\n",
    "#                         df.to_csv(os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv')) \n",
    "        except:\n",
    "            issue_files.append(file)\n",
    "with open(os.path.join(out_path,'issue_maps.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(issue_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(arr)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(arr)\n",
    "# df.to_csv(os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv')) \n",
    "df.to_csv(os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv'), encoding='utf-8',decimal='.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(out_path,f'lakesStats_{wqp_parameter}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outlier Rejection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the outliers \"free\" maps based on the selected wqpMaps and outlierMethods selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp_parameter = 'chl'\n",
    "outlier_method = 'IQR'\n",
    "# in_path = os.path.join(cwd['in'],sensor.value,refProducts.value,wqpMaps.value)\n",
    "# in_path = './temp/wqp_maps/lswt'\n",
    "# out_path = './temp/wqp_maps/lswt_OR'\n",
    "in_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered_or/{outlier_method}/{wqp_parameter}')\n",
    "out_path = os.path.join(f'./out/image_coregistration/wqp/full_coregistered_or/{outlier_method}/{wqp_parameter}/outliers')\n",
    "# in_path = os.path.join(f'./out/outlier_rejection/wqp/{outlier_method}/lswt')\n",
    "# out_path = os.path.join(f'./out/outlier_rejection/wqp/{outlier_method}/lswt/outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/229186/os-walk-without-digging-into-directories-below\n",
    "def walklevel(some_dir, level=1):\n",
    "    some_dir = some_dir.rstrip(os.path.sep)\n",
    "    assert os.path.isdir(some_dir)\n",
    "    num_sep = some_dir.count(os.path.sep)\n",
    "    for root, dirs, files in os.walk(some_dir):\n",
    "        yield root, dirs, files\n",
    "        num_sep_this = root.count(os.path.sep)\n",
    "        if num_sep + level <= num_sep_this:\n",
    "            del dirs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = walklevel(in_path, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in_path = os.path.join(cwd['in'],sensor.value,refProducts.value,wqpMaps.value)\n",
    "# out_path = os.path.join(cwd['out'],'wqp',outlierMethods.value, wqpMaps.value)\n",
    "shared_maps = list(set(os.listdir(in_path)).intersection(os.listdir(out_path)))\n",
    "missing_maps = list(set(os.listdir(in_path)) ^ set(os.listdir(out_path)))\n",
    "\n",
    "d = []\n",
    "for root, dirs, files in os.walk(in_path):\n",
    "    l = os.listdir(os.path.join(root))\n",
    "    if root.split('/')[-1]!='outliers':\n",
    "        for file in l:\n",
    "        # for file in missing_maps:\n",
    "            if ((file.endswith('.tif'))):\n",
    "                f = os.path.join(in_path,file)\n",
    "                try:\n",
    "                    # Read file\n",
    "                    print(f)\n",
    "                    src = wqp.wqp(f)\n",
    "                    src.readWQP()\n",
    "                    # Crop the lakes by the lakes \n",
    "                    src.cropRasterByFeatures(os.path.join(cwd['vector'],'simile_laghi','simile_laghi.shp'),'Nome')\n",
    "\n",
    "                    # Compute statistics for the lakes polygons\n",
    "                    src.computeStatistics(gdf_lakes, 'Nome',\"count min mean max median std percentile_25 percentile_50 percentile_75\",0)\n",
    "\n",
    "                    # Apply the outlier rejection method\n",
    "                    src.outlierRejection(method=outlierMethods.value, minLower=0, maxUpper = 100)\n",
    "\n",
    "                    # # Export the outlier rejection products\n",
    "                    # src.mergeRasterCollectionsExport(src.raster_collection, os.path.join(out_path, src.name + '.tif'))\n",
    "                    # src.mergeRasterCollectionsExport(src.outliers_collection, os.path.join(out_path,'outliers', src.name + '.tif'))\n",
    "                    src.mergeRasterCollectionsExport(src.outliers_collection, os.path.join(out_path, src.name + '.tif'))\n",
    "                    print(src.outliers_collection, os.path.join(out_path,'outliers', src.name + '.tif'))\n",
    "\n",
    "                    # Export outliers data\n",
    "                    df = wqp.wqp.exportWQPFormatStatsOutliers(src)\n",
    "                    d.append(df)\n",
    "\n",
    "                    # Export the statistics result to a file (append data if existing)\n",
    "                    out_file = os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv')\n",
    "\n",
    "                    # if os.path.exists(out_file):\n",
    "                    #     df.to_csv(os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv'),mode='a', header=False)\n",
    "                    # else:\n",
    "                    #     df.to_csv(os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv')) \n",
    "                except:\n",
    "                    # Open a file with access mode 'a'\n",
    "                    file_object = open(os.path.join(out_path,f'error_images_{sensor.value}.txt'), 'a')\n",
    "                    # Append 'hello' at the end of file\n",
    "                    file_object.write(src.name)\n",
    "                    file_object.write(\"\\n\")\n",
    "                    # Close the file\n",
    "                    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(d)\n",
    "result_df = result_df.replace(-9999, np.nan)\n",
    "result_df.loc[result_df['upperBound_Como'].isna(),['lowerBound_Como','countLower_Como','countUpper_Como','countTotal_Como','percValid_Como','percOutliers_Como']]=np.nan\n",
    "result_df.loc[result_df['upperBound_Maggiore'].isna(),['lowerBound_Maggiore','countLower_Maggiore','countUpper_Maggiore','countTotal_Maggiore','percValid_Maggiore','percOutliers_Maggiore']]=np.nan\n",
    "result_df.loc[result_df['upperBound_Lugano'].isna(),['lowerBound_Lugano','countLower_Lugano','countUpper_Lugano','countTotal_Lugano','percValid_Lugano','percOutliers_Lugano']]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(os.path.join(out_path,f'{wqp_parameter}_{outlier_method}_outliers.csv'), encoding='utf-8', decimal='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the following procedure to perform the outlier rejection for the coregistered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_path = os.path.join('./out/images_coregistration/wqp','full_coregistered',wqpMaps.value)\n",
    "out_path = os.path.join('./out/images_coregistration/wqp','full_coregistered_or',outlierMethods.value,wqpMaps.value)\n",
    "print(in_path)\n",
    "print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: apply the outlier rejection method to the missing datasets\n",
    "cor_path = './out/image_coregistration/wqp'\n",
    "# OUTLIER REJECTION FOR THE WQP COREGISTRERED MAPS\n",
    "\n",
    "in_path = os.path.join(cor_path,'full_coregistered',wqpMaps.value)\n",
    "out_path = os.path.join(cor_path,'full_coregistered_or',outlierMethods.value,wqpMaps.value)\n",
    "print(in_path)\n",
    "print(out_path)\n",
    "for root, dirs, files in os.walk(in_path):\n",
    "    for file in files:\n",
    "        if ((file.endswith('.tif')) & ([]==dirs)):\n",
    "            print(in_path,file)\n",
    "            f = os.path.join(in_path,file)\n",
    "            try:\n",
    "                # Read file\n",
    "                src = wqp.wqp(f)\n",
    "                src.readWQP()\n",
    "                # Crop the lakes by the lakes \n",
    "                src.cropRasterByFeatures(os.path.join(cwd['vector'],'simile_laghi','simile_laghi.shp'),'Nome')\n",
    "\n",
    "                # Compute statistics for the lakes polygons\n",
    "                src.computeStatistics(gdf_lakes, 'Nome',\"count min mean max median std percentile_25 percentile_50 percentile_75\",0)\n",
    "                print(src.name)\n",
    "                # Apply the outlier rejection method\n",
    "                src.outlierRejection(method=outlierMethods.value, minLower=0, maxUpper = 30)    \n",
    "\n",
    "                # Export the outlier rejection products\n",
    "                src.mergeRasterCollectionsExport(src.raster_collection, os.path.join(out_path, src.name + '.tif'))\n",
    "                src.mergeRasterCollectionsExport(src.outliers_collection, os.path.join(out_path,'outliers', src.name + '.tif'))\n",
    "\n",
    "                # Export outliers data\n",
    "                df = wqp.wqp.exportWQPFormatStatsOutliers(src)\n",
    "\n",
    "                # Export the statistics result to a file (append data if existing)\n",
    "                out_file = os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv')\n",
    "                if os.path.exists(out_file):\n",
    "                    df.to_csv(os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv'),mode='a', header=False)\n",
    "                else:\n",
    "                    df.to_csv(os.path.join(out_path,'outliers',f'lakesStats_{outlierMethods.value}_{wqpMaps.value}.csv')) \n",
    "            except:\n",
    "                # Open a file with access mode 'a'\n",
    "                file_object = open(os.path.join(out_path,f'error_images_{sensor.value}.txt'), 'a')\n",
    "                # Append 'hello' at the end of file\n",
    "                file_object.write(src.name)\n",
    "                file_object.write(\"\\n\")\n",
    "                # Close the file\n",
    "                file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapEnv (Python)",
   "language": "python",
   "name": "snapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
