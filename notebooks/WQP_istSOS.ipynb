{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Parameters - istSOS upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current notebook introduces the computation and ingestion of the aggregate descriptive statistics, on a basins level, of the Water Quality Paramenters produced under the framework of SIMILE project into the [istSOS](http://www.istsos.org/) platform. Additional information on the istSOS capabilities and REST API can be found in its [documentation](http://istsos.org/en/latest/doc/) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Working Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working libraries and Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling notebook\n",
    "\n",
    "# System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import scripts libraries for the project\n",
    "sys.path.append('./src/python')\n",
    "\n",
    "\n",
    "# Import the function to update the notebook style\n",
    "from nbConfig import (css_styling)\n",
    "\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Spatial Data\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rasterio.plot import show_hist\n",
    "\n",
    "# Import custom libraries\n",
    "import wqp_istSOS as istsos\n",
    "import wqpFunctions as wqp\n",
    "\n",
    "# Widgets\n",
    "import ipywidgets as wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Working Directories\n",
    "cwd = {\n",
    "    'local': '.',\n",
    "    'in': './out/image_coregistration/',\n",
    "    'out': './out/istSOS/',\n",
    "    'vector': './vector',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### istSOS client authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SIMILE, two different instances of istSOS have been implemented for the data upload depending on the lakes. One for lake Lugano, and a second for Lake Como and Maggiore. For this reason, it is required specifying the proper hosting endpoint, service and credentials to trigger the different procedures fot data ingestion.\n",
    "\n",
    "The hosting endpoints for each instance are the following:\n",
    "- Lake Lugano: `'https://istsos.ddns.net/'`\n",
    "- Lake Como and Maggiore: `'http://150.145.35.198:2000'`\n",
    "\n",
    "The user credentials can be found in the following env files for each lake:\n",
    "- Lake Lugano: `'../env_lugano.json'`\n",
    "- Lake Como and Maggiore: `'../env_como_maggiore.json'`\n",
    "\n",
    "The service for each lake is the following:\n",
    "- Lake Lugano: `'ceresiohourly'`\n",
    "- Lake Como: `'lariolive'`\n",
    "- Lake Maggiore: `'maggiorelive'`\n",
    "\n",
    "**Note:** The list of names for the procedures are provided in `./src/python/wqp_istSOS.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineHeaders(istSOSname, HEADERS):\n",
    "    if istSOSname=='LUGANO':\n",
    "        d = {\n",
    "            'HOST':'https://istsos.ddns.net',\n",
    "            'HEADERS':HEADERS,\n",
    "            'SERVICE':'ceresiohourly',\n",
    "            'PROCEDURE_LAKE':'LUGANO',\n",
    "            'ENV_FILE':'../env_lugano.json'\n",
    "        }\n",
    "    elif istSOSname=='COMO':\n",
    "        d = {\n",
    "            'HOST':'https://istsos.irsa.cnr.it',\n",
    "            'HEADERS':HEADERS,\n",
    "            'SERVICE':'lariolive',\n",
    "            'PROCEDURE_LAKE':'COMO',\n",
    "            'ENV_FILE':'../env_como_maggiore.json'\n",
    "        }\n",
    "    elif istSOSname=='MAGGIORE':\n",
    "        d = {\n",
    "            'HOST':'https://istsos.irsa.cnr.it',\n",
    "            'HEADERS':HEADERS,\n",
    "            'SERVICE':'maggiorelive',\n",
    "            'PROCEDURE_LAKE':'MAGGIORE',\n",
    "            'ENV_FILE':'../env_como_maggiore.json'\n",
    "        }\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = defineHeaders('COMO', istsos.istSOSClient.HEADERS)\n",
    "c = istsos.istSOSClient(HOST=headers['HOST'],\n",
    "                        HEADERS=headers['HEADERS'],\n",
    "                        SERVICE=headers['SERVICE'],\n",
    "                        PROCEDURE_LAKE=headers['PROCEDURE_LAKE'],\n",
    "                        ENV_FILE=headers['ENV_FILE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined user contains the following information to reach istSOS for the data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to trigger the different procedures for data ingestion into the plaftorm it is required to retrive its corresponding **id**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the id for the procedure using the curent client session in istSOS with the provided credentials.\n",
    "c.updateBearerToken() # Make sure that the current token for the user is still valid.\n",
    "assigned_sensor_id = c.getProcedureIDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_sensor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vector Data - Basins\n",
    "\n",
    "In this section, we import the vector layer for the computation of the aggregate statistics, based in the features of the imported layer. In this case, for the division of the lakes ata a basing level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer dataset\n",
    "gdf_basins = gpd.read_file(os.path.join(cwd['vector'],'simile_basins','simile_basins.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "gdf_basins.plot(ax = ax, edgecolor=\"black\", alpha = 0.3, column = 'LakeProc', legend = True,\\\n",
    "               legend_kwds={'loc': 'center left', 'bbox_to_anchor':(1,0.5)})\n",
    "ax.grid()\n",
    "\n",
    "scale1 = ScaleBar(\n",
    "    dx=1,\n",
    "    location='lower right',  # in relation to the whole plot\n",
    "    label_loc='left', scale_loc='bottom'  # in relation to the line\n",
    ")\n",
    "ax.add_artist(scale1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Descriptive Statistics - Basin Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, it will be possible to select the procedure used for the data upload. After selecting the procedure of interest, a sample of the data format will be requested, this sample will serve for the update of new statistics upload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Selection - Data Formatting for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure = wg.Select(\n",
    "    options = c.procedures,\n",
    "    value = c.procedures[0],\n",
    "    description = 'Select the procedure:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='50%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensor = wg.Select(\n",
    "    options = ['S3', 'L8'],\n",
    "    value = 'S3',\n",
    "    description = 'Select the sensor:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='50%', height='100px'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the procedure of interest to extract/ingest data into the selected istSOS instance.\n",
    "\n",
    "The sensor selection accounts for a further step in obtaining estimates for the Water Quality Parameters of Interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.HBox([procedure, sensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.updateBearerToken()\n",
    "data = c.getRequestSample(procedure.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample observation for the selected procedure\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Basin Stats to CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the different WQP, multiple products have been extracted. In general, the stats are computed for the WQP maps that passed through the outlier detection/rejection process with the 3$\\sigma$ filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Typology of the products\n",
    "typology_list = [\n",
    "    'chl',\n",
    "    'tsm',\n",
    "    'lswt'\n",
    "]\n",
    "# Outlie Rejection methods\n",
    "or_list = [\n",
    "    'IQR',\n",
    "    '2Sigma',\n",
    "    '3Sigma'\n",
    "]\n",
    "\n",
    "# Subset to the buffer size (same used as for the coregistration)\n",
    "featureGeometry = os.path.join(cwd['vector'],'simile_laghi_extent/simile_laghi_extent_600m_buff.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typology = wg.Select(\n",
    "    options = typology_list,\n",
    "    value = typology_list[0],\n",
    "    description = 'Select the WQP type:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='50%', height='100px'),\n",
    ")\n",
    "\n",
    "orMethod = wg.Select(\n",
    "    options = or_list,\n",
    "    value = or_list[0],\n",
    "    description = 'Select the OR method:',\n",
    "    disabled = False,\n",
    "    style = {\n",
    "        'description_width': 'auto'\n",
    "    },\n",
    "    layout = wg.Layout(width='50%', height='100px'),\n",
    ")\n",
    "\n",
    "# Widgets\n",
    "wg.HBox([typology, orMethod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(cwd['in'],'wqp','full_coregistered_or',orMethod.value,typology.value)\n",
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in_path = os.path.join(cwd['in'],'wqp',orMethod.value,typology.value)\n",
    "\n",
    "# In case it is required cropping the maps\n",
    "\n",
    "# out_path = os.path.join(in_path,'cropped')\n",
    "# shared_maps = list(set(os.listdir(in_path)).intersection(os.listdir(out_path)))\n",
    "# missing_maps = list(set(os.listdir(in_path)) ^ set(os.listdir(out_path)))\n",
    "# print(missing_maps)\n",
    "# for root, dirs, files in os.walk(in_path):\n",
    "#     for f in missing_maps:\n",
    "#         if ((f.endswith('.tif')) & (dirs==['cropped'])):\n",
    "#             chl_map = os.path.join(in_path,f)\n",
    "#             print(chl_map)\n",
    "#             wqp_map = wqp.wqp(chl_map)\n",
    "#             wqp_map.readWQP()\n",
    "#             wqp_map.cropRasterByFeatures(featureGeometry,'Nome')\n",
    "#             d_temp = wqp_map.crops['wqp']['crop']\n",
    "#             d_temp[d_temp<0] = 0\n",
    "#             wqp_map.crops['wqp']['crop'] = d_temp\n",
    "#             wqp_map.saveMaskedImage(os.path.join(out_path,wqp_map.name+'.tif'),'wqp',band=1)\n",
    "#             wqp_map.image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if typology.value in ['chl','tsm']:\n",
    "    in_path = os.path.join(cwd['in'],'wqp','full_coregistered_or',orMethod.value,typology.value)\n",
    "    stats = os.path.join(in_path,f'lakesStats_{typology.value}.csv')\n",
    "elif typology.value in ['lswt']:\n",
    "    in_path = os.path.join('./out/outlier_rejection/wqp',orMethod.value,typology.value)\n",
    "    stats = os.path.join('./out/outlier_rejection/wqp',orMethod.value,typology.value,f'lakesStats_{typology.value}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take into account that some of the files have already been analyzed\n",
    "data = []\n",
    "for root, dirs, files in os.walk(in_path):\n",
    "    if root.split('/')[-1]!='outliers':\n",
    "        if os.path.exists(stats):\n",
    "            df = pd.read_csv(stats)\n",
    "            stats_file_names = set(list(df['name']+'.tif'))\n",
    "            missing_stats = list(stats_file_names ^ set(os.listdir(in_path)))\n",
    "        else:\n",
    "            missing_stats = files\n",
    "        for file in missing_stats:\n",
    "            if ((file.endswith('.tif')) & (root.split('\\\\')[-1]!='outliers')):\n",
    "                print(root,file)\n",
    "                f = os.path.join(root,file)\n",
    "\n",
    "                # Read file\n",
    "                src = wqp.wqp(f)\n",
    "                src.readWQP()\n",
    "                src.name\n",
    "\n",
    "                # Compute statistics for the basins polygons\n",
    "                src.computeStatistics(gdf_basins, 'LakeProc',\"count min mean max median std  percentile_25 percentile_50 percentile_75\", -9999)\n",
    "\n",
    "                # Format output\n",
    "                data.append(wqp.wqp.exportWQPFormatStats(src))\n",
    "\n",
    "df = pd.concat(data)\n",
    "# Add values to csv file\n",
    "istsos.appendStatsFile(df, stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products for submission to istSOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join('./out/istSOS','lakeStats_CHL_TSM_submit.csv')\n",
    "# file_name = os.path.join('./out/istSOS','lakeStats_LSWT.csv')\n",
    "df = pd.read_csv(file_name,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['std_CO_E','std_CO_N','std_CO_N','std_MA_ALL','std_LUG_N','std_LUG_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filters:\n",
    "    df = df[df[f]>0]\n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('./out/istSOS',f'lakeStats_CHL_TSM_submit.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### istSOS JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of S3, it is needed to import both reference data files for the computed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the statistics files\n",
    "# file_name = os.path.join(in_path,f'lakesStats_{typology.value}_submit.csv')\n",
    "# file_name = os.path.join('./out/istSOS',f'lakeStats_CHL_TSM_submit.csv')\n",
    "file_name = os.path.join('./out/istSOS',f'lakeStats_LSWT_submit.csv')\n",
    "df = pd.read_csv(file_name,delimiter=\",\")\n",
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.sort_values(by=['date'])\n",
    "df = df.round(2)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istsos.istSOSClient.WQP_PROCEDURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: update the updateDataRequest and resultsWQPvalues functions for the new procedures naming convention\n",
    "STATISTIC = 'std'\n",
    "a = istsos.updateDataRequest(df=df,\n",
    "                    dataSample=data, \n",
    "                    WQP_DEFINITIONS=istsos.istSOSClient.WQP_DEFINITIONS,\n",
    "                    WQP_PROCEDURES=istsos.istSOSClient.WQP_PROCEDURES,\n",
    "                    PROCEDURE=procedure.value,\n",
    "                    STATISTIC=STATISTIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Get Observation\n",
    "# SERVICE_NAME = 'demo'\n",
    "# OFFERING_NAME = 'temporary'\n",
    "# PROCEDURE_NAME = 'SATELLITE_CHL_TURB_CO_EAST'\n",
    "# DEFINITION_URNs = 'urn:ogc:def:parameter:x-istsos:1.0:water:Chl'\n",
    "# BEGIN_TIME = \"2020-01-01T00:01:00+01\"\n",
    "# END_TIME = \"2020-01-17T00:01:00+01\"\n",
    "\n",
    "# url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "# url_test =f\"{url_base}/wa/istsos/services/{SERVICE_NAME}/operations/getobservation/offerings/{OFFERING_NAME}/procedures/{PROCEDURE_NAME}/observedproperties/{DEFINITION_URNs}/eventtime/{BEGIN_TIME}/{END_TIME}\"\n",
    "# resp = requests.get(url_test, headers=c.requestHeaders)\n",
    "# resp.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WQP_PROCEDURES = ['CHL','TURB','WT']\n",
    "# a = procedure.value.split('_')\n",
    "# wqps = list(set(a).intersection(WQP_PROCEDURES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INSERT OBSERVATION PARAMETERS\n",
    "\n",
    "# ########## PARAMETERS TO BE EDITED ####################\n",
    "# LAKE = 'CO' # {CO: COMO, LU: LUGANO, MA: MAGGIORE}\n",
    "# WQP_INPUT = ['LSWT'] #['LSWT','CHL','TSM']\n",
    "# #######################################################\n",
    "\n",
    "# DATE_START = pytz.utc.localize(df.date.min()).isoformat().replace('+00:00','Z')\n",
    "# DATE_END = pytz.utc.localize(df.date.max()).isoformat().replace('+00:00','Z')\n",
    "\n",
    "\n",
    "# if LAKE == 'CO':\n",
    "#     BASINS_LIST = ['CO_NORTH','CO_EAST','CO_WEST']\n",
    "# elif LAKE == 'LU':\n",
    "#     BASINS_LIST = ['LU_EAST','LU_WEST']\n",
    "# elif LAKE == 'MA':\n",
    "#     BASINS_LIST = ['MA_ALL']\n",
    "    \n",
    "# # Observed properties\n",
    "# OP_COMPOSITE_PHENOMENON_ID = 'comp_1' #random name?\n",
    "# OP_COMPOSITE_PHENOMENON_DIMENSION = '{}'.format(len(WQP_INPUT)+1) #int number of input observed variables (not observations)\n",
    "# OP_COMPONENT = [\"urn:ogc:def:parameter:x-istsos:1.0:time:iso8601\"]\n",
    "# for wqp in WQP_INPUT: #Observed parameters names: {'lswt':'water-temperature';'chl'}\n",
    "#     if 'LSWT' in wqp:\n",
    "#         OP_COMPONENT.append(\"urn:ogc:def:parameter:x-istsos:1.0:water-temperature\")\n",
    "#     elif 'CHL' in wqp:\n",
    "#         OP_COMPONENT.append(\"urn:ogc:def:parameter:x-istsos:1.0:water:Chl\")\n",
    "#     elif 'TSM' in wqp:\n",
    "#         OP_COMPONENT.append(\"urn:ogc:def:parameter:x-istsos:1.0:water:Turb\")\n",
    "\n",
    "# #Results\n",
    "# RES_DA_ELEMENT_COUNT = OP_COMPOSITE_PHENOMENON_DIMENSION # Does this parameter have the same magnitude as the composite dimension?\n",
    "# RES_DA_FIELDS = [\n",
    "#     {\n",
    "#         \"name\": \"Time\",\n",
    "#         \"definition\": \"urn:ogc:def:parameter:x-istsos:1.0:time:iso8601\"\n",
    "#     },\n",
    "# ]\n",
    "# for wqp in WQP_INPUT: #Observed parameters names: {'lswt':'water-temperature';'chl'}\n",
    "#     if 'LSWT' == wqp:\n",
    "#         RES_DA_FIELDS.append(\n",
    "#             {\n",
    "#                 \"name\": \"water-temperature\",\n",
    "#                 \"definition\":\"urn:ogc:def:parameter:x-istsos:1.0:water-temperature\",\n",
    "#                 \"uom\":\"\\u00b0C\"\n",
    "#             }\n",
    "#         )\n",
    "#     elif 'CHL' == wqp:\n",
    "#         RES_DA_FIELDS.append(\n",
    "#             {\n",
    "#                 \"name\": \"water-Chl\",\n",
    "#                 \"definition\":\"urn:ogc:def:parameter:x-istsos:1.0:water:Chl\",\n",
    "#                 \"uom\":\"mg/m^3\"\n",
    "#             }\n",
    "#         )\n",
    "#     elif 'TSM' == wqp:\n",
    "#         RES_DA_FIELDS.append(\n",
    "#             {\n",
    "#                 \"name\": \"water-Turb\",\n",
    "#                 \"definition\":\"urn:ogc:def:parameter:x-istsos:1.0:water:Turb\",\n",
    "#                 \"uom\":\"g/m^3\"\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "# # Create insertObsevartion model for istSOS depending on the procedure.\n",
    "# for PROCEDURE in PROCEDURES_LIST:\n",
    "#     obs = {\n",
    "#         \"AssignedSensorId\":f\"{ASSIGNED_SENSOR_ID[PROCEDURE]}\",\n",
    "#         \"ForceInsert\":\"false\",\n",
    "#         \"Observation\":{\n",
    "#             \"name\":f\"{PROCEDURE}\",\n",
    "#             \"samplingTime\":{\n",
    "#             \"beginPosition\":f\"{DATE_START}\",\n",
    "#             \"endPosition\":f\"{DATE_END}\"\n",
    "#             },\n",
    "#             \"procedure\":f\"urn:ogc:def:procedure:x-istsos:1.0:{PROCEDURE}\",\n",
    "#             \"observedProperty\": {\n",
    "#                 \"CompositePhenomenon\":{\n",
    "#                     \"id\":f\"{OP_COMPOSITE_PHENOMENON_ID}\", \n",
    "#                     \"dimension\":f\"{OP_COMPOSITE_PHENOMENON_DIMENSION}\", \n",
    "#                     \"name\":\"timeSeriesOfObservations\"\n",
    "#                 },\n",
    "#                 \"component\": OP_COMPONENT\n",
    "#             },\n",
    "#             \"featureOfInterest\":{ # Is it necessary to assign the value to a geometry? \n",
    "#                 \"name\":f\"urn:ogc:def:feature:x-istsos:1.0:Point:{PROCEDURE}\",\n",
    "#                 \"geom\":f\"{istsos.getGMLfeature(os.path.join(cwd['out'],'procedures_istSOS'), PROCEDURE+\"_point\")}\" \n",
    "#             },\n",
    "#             \"result\": {\n",
    "#                 \"DataArray\": {\n",
    "#                     \"elementCount\":f\"{RES_DA_ELEMENT_COUNT}\",\n",
    "#                     \"field\": RES_DA_FIELDS,\n",
    "#                     \"values\": istsos.resultsWQPvalues(df,'_'.join(PROCEDURE.split('_')[-2:])),#BASIN\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     print('_'.join(PROCEDURE.split('_')[-2:]))\n",
    "#     with open(os.path.join(cwd['out'],f\"{PROCEDURE}.json\"), \"w\", encoding=\"UTF-8\") as outfile:\n",
    "#         json.dump(obs, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion to istSOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {\n",
    "    \"AssignedSensorId\":f\"{assigned_sensor_id[procedure.value]}\",\n",
    "    \"ForceInsert\":\"true\",\n",
    "    \"Observation\": a\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(cwd['out'],f\"{procedure.value}.json\"), \"w\", encoding=\"UTF-8\") as outfile:\n",
    "    json.dump(obs, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name_json = f'{procedure.value}.json'\n",
    "filepath = os.path.join(cwd['out'],file_name_json)\n",
    "print(filepath)\n",
    "f = open(filepath)\n",
    "\n",
    "data = json.load(f)\n",
    "d=json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.updateBearerToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Insert Observation into istSOS test\n",
    "url = headers['HOST']+'/istsos/wa/istsos/services/'+headers['SERVICE']+'/operations/insertobservation'\n",
    "# response = requests.post(url,data=json.dumps(obs),headers=c.requestHeaders)\n",
    "response = requests.post(url,data=d,headers=c.requestHeaders)\n",
    "print(response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing istSOS API  calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "url_test =f\"{url_base}/wa/istsos/services/{istsos.istSOSClient.SERVICE}/procedures/operations/getlist\"\n",
    "resp = requests.get(url_test,headers=c.requestHeaders)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "url_test =f\"{url_base}/wa/istsos/services/demo/procedures/operations/geojson\"\n",
    "resp = requests.get(url_test, data=payload, headers=headers_req)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Offerings\n",
    "url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "url_test =f\"{url_base}/wa/istsos/services/demo/offerings/operations/getlist\"\n",
    "resp = requests.get(url_test, data=payload, headers=headers_req)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Observation\n",
    "SERVICE_NAME = 'ceresiohourly'\n",
    "OFFERING_NAME = 'temporary'\n",
    "PROCEDURE_NAME = procedure.value\n",
    "# DEFINITION_URNs = 'urn:ogc:def:parameter:x-istsos:1.0:water:Chl:a&urn:ogc:def:parameter:x-istsos:1.0:water:TSS'\n",
    "DEFINITION_URNs = 'urn:ogc:def:parameter:x-istsos:1.0:water:temperature'\n",
    "BEGIN_TIME = \"2019-01-04T09:54:16Z\"\n",
    "END_TIME = \"2022-08-26T09:58:18Z\"\n",
    "\n",
    "url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "url_test =f\"{url_base}/wa/istsos/services/{SERVICE_NAME}/operations/getobservation/offerings/{OFFERING_NAME}/procedures/{PROCEDURE_NAME}/observedproperties/{DEFINITION_URNs}/eventtime/{BEGIN_TIME}/{END_TIME}\"\n",
    "resp = requests.get(url_test, headers=c.requestHeaders)\n",
    "resp.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Observation\n",
    "SERVICE_NAME = 'demo'\n",
    "OFFERING_NAME = 'temporary'\n",
    "PROCEDURE_NAME = 'SATELLITE_CHL_TURB_CO_WEST'\n",
    "DEFINITION_URNs = 'urn:ogc:def:parameter:x-istsos:1.0:water:Chl'\n",
    "BEGIN_TIME = \"2019-01-01T00:01:00+01\"\n",
    "END_TIME = \"2022-01-17T00:01:00+01\"\n",
    "\n",
    "url_base = \"https://istsos.ddns.net/istsos/\"\n",
    "url_test =f\"{url_base}/wa/istsos/services/{SERVICE_NAME}/operations/getobservation/offerings/{OFFERING_NAME}/procedures/{PROCEDURE_NAME}/observedproperties/:/eventtime/last\"\n",
    "resp = requests.get(url_test, headers=c.requestHeaders)\n",
    "resp.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapEnv (Python)",
   "language": "python",
   "name": "snapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2083f749abe79a73b2e875f8f94e60d7a5a252ea6ab5c8bd42b8c1efbd65b428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
